# OnDi - On-Device AI Model

> **100% From Scratch | 100% Owned License | Coding & English Specialized**

OnDiëŠ” ì²˜ìŒë¶€í„° ì§ì ‘ ì„¤ê³„í•˜ê³  í•™ìŠµí•œ ì»¤ìŠ¤í…€ AI ëª¨ë¸ì…ë‹ˆë‹¤. ì½”ë”©ê³¼ ì˜ì–´ì— íŠ¹í™”ë˜ì–´ ìˆìœ¼ë©°, ì˜¨ë””ë°”ì´ìŠ¤ ë°°í¬ë¥¼ ëª©í‘œë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

## Quick Start (ë°”ë¡œ ì‚¬ìš©í•˜ê¸°)

**í•™ìŠµ ì—†ì´ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥!** ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

```bash
# 1. Clone
git clone https://github.com/junhuhan99/ondi.git
cd ondi

# 2. Install
pip install torch transformers

# 3. Run
python inference.py --checkpoint ./checkpoints/final --interactive
```

## Available Models

| Version | Parameters | Focus | Val Loss | Status |
|---------|------------|-------|----------|--------|
| **v1** | 26M | Coding + English | 0.0750 | âœ… Available |
| **v2** | 475M | Python 85% + English Conversation | - | ğŸ”„ Training |

## Features

- **100% Custom Architecture**: Transformer ëª¨ë¸ì„ ì²˜ìŒë¶€í„° ì§ì ‘ ì„¤ê³„
- **100% Owned License**: ëª¨ë“  ì½”ë“œì™€ ëª¨ë¸ ê°€ì¤‘ì¹˜ì— ëŒ€í•œ ì™„ì „í•œ ì†Œìœ ê¶Œ
- **Pre-trained Weights Included**: í•™ìŠµ ì—†ì´ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥
- **Coding Specialized**: Python, JavaScript ë“± í”„ë¡œê·¸ë˜ë° ì½”ë“œ ìƒì„±
- **English Specialized**: ìì—°ìŠ¤ëŸ¬ìš´ ì˜ì–´ í…ìŠ¤íŠ¸ ìƒì„±
- **On-Device Ready**: ê²½ëŸ‰í™”ëœ ëª¨ë¸ë¡œ ë¡œì»¬ ì‹¤í–‰ ê°€ëŠ¥

## Model Architecture

```
OnDi Model (GPT-style Decoder-only Transformer)
â”œâ”€â”€ Token Embedding
â”œâ”€â”€ Position Embedding
â”œâ”€â”€ Transformer Blocks (x8-24)
â”‚   â”œâ”€â”€ Multi-Head Self-Attention
â”‚   â”œâ”€â”€ Layer Normalization (Pre-norm)
â”‚   â””â”€â”€ Feed-Forward Network (GELU)
â”œâ”€â”€ Final Layer Normalization
â””â”€â”€ Language Model Head (weight-tied)
```

### Model Configurations

| Size | Parameters | d_model | Layers | Heads | Context |
|------|------------|---------|--------|-------|---------|
| v1 (Small) | 26M | 512 | 8 | 8 | 1024 |
| v2 (Large) | 475M | 1280 | 24 | 20 | 1024 |

## Installation

```bash
# Clone repository
git clone https://github.com/junhuhan99/ondi.git
cd ondi

# Create virtual environment (optional)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
.\venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```

## Usage

### Inference (ì¶”ë¡ )

```bash
# Interactive mode
python inference.py --checkpoint ./checkpoints/final --interactive

# Single prompt
python inference.py --checkpoint ./checkpoints/final --prompt "def hello_world():"
```

### Python API

```python
from inference import OnDiInference

# Load pre-trained model
model = OnDiInference("./checkpoints/final")

# Generate code
code = model.generate(
    prompt="def fibonacci(n):",
    max_new_tokens=200,
    temperature=0.8
)
print(code)

# Generate English text
text = model.generate(
    prompt="Machine learning is",
    max_new_tokens=100
)
print(text)
```

## Training (Optional)

ì§ì ‘ í•™ìŠµí•˜ê³  ì‹¶ë‹¤ë©´:

### v1 Model (26M)

```bash
python train.py --model_size small --max_steps 30000
```

### v2 Model (475M) - Python 85% + English Conversation

```bash
python train_v2.py --batch_size 2 --max_steps 50000
```

## Project Structure

```
ondi/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model.py          # Transformer model architecture
â”‚   â”œâ”€â”€ tokenizer.py      # BPE tokenizer implementation
â”‚   â”œâ”€â”€ dataset.py        # Dataset preparation (v1)
â”‚   â””â”€â”€ dataset_v2.py     # Dataset preparation (v2: Python 85%)
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ final/
â”‚       â”œâ”€â”€ model.pt      # Pre-trained weights (26M)
â”‚       â”œâ”€â”€ config.json   # Model configuration
â”‚       â””â”€â”€ tokenizer/    # Trained BPE tokenizer
â”œâ”€â”€ train.py              # Training script (v1)
â”œâ”€â”€ train_v2.py           # Training script (v2: 475M)
â”œâ”€â”€ inference.py          # Inference script
â”œâ”€â”€ requirements.txt      # Dependencies
â””â”€â”€ README.md             # Documentation
```

## Training Details

### v1 Model
- **Data**: Coding + English mixed
- **Steps**: 30,000
- **Final Val Loss**: 0.0750
- **Training Time**: ~1 hour on T4

### v2 Model (In Progress)
- **Data**: Python 85% + English Conversation 15%
- **Steps**: 50,000
- **Parameters**: 475M
- **Expected Training Time**: ~6 hours on T4

## Hardware Requirements

### Inference
- CPU: Any modern CPU
- RAM: 2GB+ (v1), 4GB+ (v2)
- GPU: Optional (faster with CUDA)

### Training
- GPU: NVIDIA T4 (16GB) or better
- RAM: 32GB+
- Storage: 100GB+

## License

**This project is 100% owned by the creator.**

All code, model architecture, and trained weights are original work and fully owned by the repository owner (Jun Hu Han). You may use, modify, and distribute this project according to your needs.

## Technical Specifications

### Tokenizer
- Type: Byte-Pair Encoding (BPE)
- Vocabulary Size: ~1,000-32,000 tokens (varies by version)
- Special Tokens: `<pad>`, `<unk>`, `<bos>`, `<eos>`

### Training Configuration
- Optimizer: AdamW (Î²1=0.9, Î²2=0.95)
- Learning Rate: 2e-4 ~ 3e-4 with warmup and cosine decay
- Weight Decay: 0.1
- Gradient Clipping: 1.0
- Mixed Precision: FP16 (AMP)

### Architecture
- Pre-LayerNorm (stable training)
- GELU activation
- Weight tying (embedding â†” output)
- Causal attention mask

## Citation

```bibtex
@software{ondi2024,
  title = {OnDi: On-Device AI Model for Coding and English},
  author = {Jun Hu Han},
  year = {2024},
  url = {https://github.com/junhuhan99/ondi}
}
```

## Author

**Jun Hu Han** (junhuhan99)

- Built with PyTorch
- Trained on AWS EC2 with NVIDIA T4 GPU
- 100% From Scratch Implementation
